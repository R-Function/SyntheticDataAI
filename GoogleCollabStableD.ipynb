{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers transformers accelerate torch --quiet"
      ],
      "metadata": {
        "id": "DMaNYXmvNGMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import zipfile\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline, LMSDiscreteScheduler\n",
        "\n",
        "def parse_captions_file(filename):\n",
        "    \"\"\"\n",
        "    Parses a text file with groups of captions.\n",
        "\n",
        "    Expected format for each group (groups start with a number and a dot):\n",
        "\n",
        "    Example group:\n",
        "\n",
        "    1. A long caption about the subject (for metadata only)\n",
        "    A small caption 1\n",
        "    A small caption 2\n",
        "    A small caption 3\n",
        "    A small caption 4\n",
        "    A small caption 5\n",
        "\n",
        "    Returns a list of dictionaries with keys:\n",
        "      - \"long_caption\": the long description (with the leading number and dot removed)\n",
        "      - \"small_captions\": list of 5 small captions (used for image generation)\n",
        "    \"\"\"\n",
        "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
        "        text = f.read()\n",
        "\n",
        "\n",
        "    groups_raw = re.split(r'(?=\\d+\\.\\s)', text)\n",
        "    groups_raw = [group.strip() for group in groups_raw if group.strip()]\n",
        "\n",
        "    groups = []\n",
        "    for group in groups_raw:\n",
        "\n",
        "        lines = [line.strip() for line in group.split(\"\\n\") if line.strip()]\n",
        "        if len(lines) < 6:\n",
        "            print(\"Skipping a group (not enough lines):\", lines)\n",
        "            continue\n",
        "\n",
        "\n",
        "        long_caption_line = lines[0]\n",
        "        if \".\" in long_caption_line:\n",
        "            parts = long_caption_line.split(\".\", 1)\n",
        "            long_caption = parts[1].strip()\n",
        "        else:\n",
        "            long_caption = long_caption_line\n",
        "\n",
        "\n",
        "        small_captions = lines[1:6]\n",
        "        groups.append({\n",
        "            \"long_caption\": long_caption,\n",
        "            \"small_captions\": small_captions\n",
        "        })\n",
        "\n",
        "    return groups\n"
      ],
      "metadata": {
        "id": "73qxJPAYNI3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "captions_file = \"captions.txt\"\n",
        "if not os.path.exists(captions_file):\n",
        "    print(f\"Error: {captions_file} not found.\")\n",
        "else:\n",
        "    caption_groups = parse_captions_file(captions_file)\n",
        "    print(f\"Found {len(caption_groups)} caption groups.\")\n"
      ],
      "metadata": {
        "id": "FVLbT4vcNI6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_inference_steps = 100\n",
        "guidance_scale = 7.5\n",
        "width, height = 512, 512\n",
        "seed = 42\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
        "pipe = pipe.to(device)\n",
        "pipe.scheduler = LMSDiscreteScheduler.from_config(pipe.scheduler.config)\n",
        "generator = torch.Generator(device).manual_seed(seed)\n",
        "negative_prompt = \"blurry, oversaturated, low resolution, deformed\"\n",
        "\n",
        "\n",
        "output_folder = \"generated_images\"\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "    print(f\"Created folder: {output_folder}\")\n",
        "\n",
        "\n",
        "metadata_lines = []\n",
        "for idx, group in enumerate(caption_groups):\n",
        "    small_captions = group[\"small_captions\"]\n",
        "    prompt = \", \".join(small_captions)\n",
        "    print(f\"Generating image {idx} with prompt: {prompt}\")\n",
        "\n",
        "    result = pipe(\n",
        "        prompt=prompt,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_inference_steps=num_inference_steps,\n",
        "        guidance_scale=guidance_scale,\n",
        "        generator=generator,\n",
        "        width=width,\n",
        "        height=height\n",
        "    )\n",
        "    image = result.images[0]\n",
        "    image_filename = os.path.join(output_folder, f\"generated_image_{idx}.png\")\n",
        "    image.save(image_filename)\n",
        "    print(f\"Saved image {idx} as {image_filename}\")\n",
        "\n",
        "\n",
        "    for branch_idx in range(5):\n",
        "        caption_for_branch = small_captions[branch_idx]\n",
        "        line = f\"{os.path.basename(image_filename)}.jpg#{branch_idx} {caption_for_branch}\"\n",
        "        metadata_lines.append(line)\n"
      ],
      "metadata": {
        "id": "QrVTT-AYNI-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadata_filename = \"output_metadata.txt\"\n",
        "with open(metadata_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "    for line in metadata_lines:\n",
        "        f.write(line + \"\\n\")\n",
        "print(f\"Wrote metadata to {metadata_filename}\")\n",
        "\n",
        "zip_filename = \"generated_images.zip\"\n",
        "with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "    for root, _, files in os.walk(output_folder):\n",
        "        for file in files:\n",
        "            filepath = os.path.join(root, file)\n",
        "            arcname = os.path.relpath(filepath, output_folder)\n",
        "            zipf.write(filepath, arcname)\n",
        "print(f\"Created zip file: {zip_filename}\")\n"
      ],
      "metadata": {
        "id": "j8Yn0F2qNJD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(zip_filename)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "AJOjCXg6NS4G",
        "outputId": "aa70b887-814f-417a-abc3-1b4af57a23b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_22e99951-c167-4657-816c-1a8e31cc8c83\", \"generated_images.zip\", 251057709)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}